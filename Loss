def d_lin_reg_th0(x, th, th0):
    """
    Parameters:
        x is d by n : input data
        th is d by 1 : weights
        th0 is 1 by 1 or scalar
    Returns:
        1 by n array : gradient of lin_reg(x, th, th0) with respect to th0
    """
    return np.array([x[1]])
    
def d_square_loss_th0(x, y, th, th0):
    """
    Parameters:
        x is d by n : input data
        y is 1 by n : output regression values
        th is d by 1 : weights
        th0 is 1 by 1 or scalar
    Returns:
        1 by n array : gradient of square_loss(x, y, th, th0) with respect to th0.
    
    This function should be a one-line expression that uses lin_reg and
    d_lin_reg_th0.
    """
    reg = d_lin_reg_th0(x, th, th0)
    return -2 * (y - lin_reg(x, th, th0)) * reg

def d_mean_square_loss_th0(x, y, th, th0):
    """
    Parameters:
        Same as above
    Returns:
        1 by 1 array : gradient of mean_square_loss(x, y, th, th0) with respect to th0.
    
    This function should be a one-line expression that uses d_square_loss_th0.
    """
    return np.mean(d_square_loss_th0(x, y, th, th0), axis = 1, keepdims = True)
