def d_lin_reg_th(x, th, th0):
    """
    Parameters:
        x is d by n : input data
        th is d by 1 : weights
        th0 is 1 by 1 or scalar
    Returns:
        d by n array : gradient of lin_reg(x, th, th0) with respect to th
    """
    return x
    
def d_square_loss_th(x, y, th, th0):
    """
    Parameters:
        x is d by n : input data
        y is 1 by n : output regression values
        th is d by 1 : weights
        th0 is 1 by 1 or scalar
    Returns:
        d by n array : gradient of square_loss(x, y, th, th0) with respect to th.
    
    This function should be a one-line expression that uses lin_reg and
    d_lin_reg_th.
    """
    return -2 * (y - lin_reg(x, th, th0)) * d_lin_reg_th(x, th, th0)

def d_mean_square_loss_th(x, y, th, th0):
    """
    Parameters:
        Same as above
    Returns:
        d by 1 array : gradient of mean_square_loss(x, y, th, th0) with respect to th.
    
    This function should be a one-line expression that uses d_square_loss_th.
    """
    return np.mean(d_square_loss_th(x, y, th, th0), axis = 1, keepdims = True)
