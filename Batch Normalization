class BatchNorm(Module):    
    def __init__(self, m):
        np.random.seed(0)
        self.eps = 1e-20
        self.m = m  # number of input channels
        
        # Init learned shifts and scaling factors
        self.B = np.zeros([self.m, 1]) # m x 1
        self.G = np.random.normal(0, 1.0 * self.m ** (-.5), [self.m, 1]) # m x 1
        
    # Works on m x b matrices of m input channels and b different inputs
    def forward(self, Z):# Z is m x K: m input channels and mini-batch size K
        # Store last inputs and K for next backward() call
        self.Z = Z
        self.K = Z.shape[1]
        
        self.mus = np.mean(self.Z,axis=1,keepdims=True)  # Your Code
        self.vars = np.var(self.Z,axis=1,keepdims=True)  # Your Code

        # Normalize inputs using their mean and standard deviation
        self.norm = (self.Z-self.mus)/(np.sqrt(self.vars)+self.eps) # Your Code
            
        # Return scaled and shifted versions of self.norm
        return self.G*self.norm+self.B  # Your Code

    def backward(self, dLdZ):
        # Re-usable constants
        std_inv = 1/np.sqrt(self.vars+self.eps)
        Z_min_mu = self.Z-self.mus
        
        dLdnorm = dLdZ * self.G
        dLdVar = np.sum(dLdnorm * Z_min_mu * -0.5 * std_inv**3, axis=1, keepdims=True)
        dLdMu = np.sum(dLdnorm*(-std_inv), axis=1, keepdims=True) + dLdVar * (-2/self.K) * np.sum(Z_min_mu, axis=1, keepdims=True)
        dLdX = (dLdnorm * std_inv) + (dLdVar * (2/self.K) * Z_min_mu) + (dLdMu/self.K)
        
        self.dLdB = np.sum(dLdZ, axis=1, keepdims=True)
        self.dLdG = np.sum(dLdZ * self.norm, axis=1, keepdims=True)
        return dLdX

    def sgd_step(self, lrate):
        self.B = self.B-lrate*self.dLdB  # Your Code
        self.G = self.G-lrate*self.dLdG  # Your Code
        return 
